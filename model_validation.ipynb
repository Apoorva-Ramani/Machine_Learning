{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "model_validation.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjcd7xw8gjwU"
      },
      "source": [
        "# Default project: Model validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUBn3vTjgjwV"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2xV0hWXgjwV"
      },
      "source": [
        "Let's first establish where our dataset is located."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq38V3J8gjwV"
      },
      "source": [
        "training_folder = 'training_data/'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb0f5NoPgjwV"
      },
      "source": [
        "We are told that the dataset has one file for each class *k*=0,1,2,... labeled 'Class*k*.csv'.  When that file is loaded, it produces a matrix where the rows contain the samples, the last column contains the label, and the other columns contain the features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlItaylBgjwV"
      },
      "source": [
        "Let's load the class files one-by-one until there are none left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlDwSx5vgjwV",
        "outputId": "59a7c85e-10e3-4a67-b451-cb2f1fc862f4"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# instantiate empty arrays for features and labels\n",
        "X = np.array([])\n",
        "y = np.array([])\n",
        "k = 0 # initialize\n",
        "\n",
        "# load data from the relevant files\n",
        "while True:\n",
        "    try:\n",
        "        # load data file\n",
        "        class_k = np.loadtxt(training_folder + 'Class{:}.csv'.format(k))\n",
        "        # extract features and labels\n",
        "        class_k_features = class_k[:,:-1] # extract features\n",
        "        class_k_labels  = class_k[:,-1].astype(np.int) # labels; convert to int\n",
        "        # append the features and labels to the arrays\n",
        "        X = np.vstack([X,class_k_features]) if X.size else class_k_features\n",
        "        y = np.hstack([y,class_k_labels]) if y.size else class_k_labels\n",
        "        # increment counter\n",
        "        k += 1\n",
        "    except:\n",
        "        print('loaded %i classes of training data' %k)\n",
        "        break\n",
        "\n",
        "# examine shape\n",
        "num_classes = k\n",
        "num_features = X.shape[1]\n",
        "num_samples = X.shape[0]\n",
        "\n",
        "print('unique labels: ', np.unique(y))\n",
        "print('number of features: ', num_features)\n",
        "print('number of samples: ', num_samples)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded 20 classes of training data\n",
            "unique labels:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
            "number of features:  20\n",
            "number of samples:  100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWQFnQvJhnoQ"
      },
      "source": [
        "import sklearn.preprocessing\n",
        "\n",
        "# standardize dataset\n",
        "X = sklearn.preprocessing.scale(X)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBg4GbgZgjwW"
      },
      "source": [
        "### Load and validate a trained sk-learn model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u091eDg7hUk5"
      },
      "source": [
        " Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R2dL_kdgjwW",
        "outputId": "9335835e-7945-45eb-df4a-e000bc11383b"
      },
      "source": [
        "import pickle\n",
        "\n",
        "sklearn_model_file = 'best_logreg.sav'\n",
        "\n",
        "# load a trained instance of sklearn.linear_model.LogisticRegression\n",
        "model = pickle.load(open(sklearn_model_file,'rb'))\n",
        "\n",
        "# predict\n",
        "y_hat = model.predict(X)\n",
        "\n",
        "# evaluate\n",
        "acc = np.mean(y_hat == y)\n",
        "print('accuracy of model: ',acc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of model:  0.8701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM1o3AEsic0x"
      },
      "source": [
        "SVM with RBF kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIIdJkQ_h_SI",
        "outputId": "0a3fc9a7-4e6c-4724-b4c4-f98890e18d0b"
      },
      "source": [
        "sklearn_model_file = 'best_svm.sav'\n",
        "\n",
        "# load a trained instance of sklearn.linear_model.LogisticRegression\n",
        "model = pickle.load(open(sklearn_model_file,'rb'))\n",
        "\n",
        "# predict\n",
        "y_hat = model.predict(X)\n",
        "\n",
        "# evaluate\n",
        "acc = np.mean(y_hat == y)\n",
        "print('accuracy of model: ',acc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of model:  0.91016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ffwf1Nmihy-"
      },
      "source": [
        "XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoNMipapikUH",
        "outputId": "7fa70f5f-e9f9-42cb-cf0e-2fdd37d5c6d3"
      },
      "source": [
        "sklearn_model_file = 'best_xgboost.sav'\n",
        "\n",
        "# load a trained instance of sklearn.linear_model.LogisticRegression\n",
        "model = pickle.load(open(sklearn_model_file,'rb'))\n",
        "\n",
        "# predict\n",
        "y_hat = model.predict(X)\n",
        "\n",
        "# evaluate\n",
        "acc = np.mean(y_hat == y)\n",
        "print('accuracy of model: ',acc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of model:  0.936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ujKQiIZiwxf"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMsUDpM3i8dw",
        "outputId": "3fa59f43-6d11-4e5c-b018-2a672e8b0d8d"
      },
      "source": [
        "import bz2\n",
        "import requests\n",
        "\n",
        "# download a trained instance of random forest\n",
        "url = 'https://ml-model-hosting.web.app/best_RF.pbz2'\n",
        "r = requests.get(url)\n",
        "open('best_RF.pbz2', 'wb').write(r.content)\n",
        "print(\"Downloaded as best_RF.pbz2.\")\n",
        "\n",
        "sklearn_model_file = 'best_RF.pbz2'\n",
        "model = pickle.load(bz2.BZ2File(sklearn_model_file,'rb'))\n",
        "\n",
        "# predict\n",
        "y_hat = model.predict(X)\n",
        "\n",
        "# evaluate\n",
        "acc = np.mean(y_hat == y)\n",
        "print('accuracy of model: ',acc)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded as best_RF.pbz2.\n",
            "accuracy of model:  0.96731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOkXCRY-gjwX"
      },
      "source": [
        "### Load and validate a trained PyTorch model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C50pImuvgjwX",
        "outputId": "d86de4bf-7cb5-4c56-c24a-efebf0e28523"
      },
      "source": [
        "import torch\n",
        "\n",
        "# load a trained PyTorch model (see 'pytorch_saving_demo.ipynb')\n",
        "mlr_torch = torch.jit.load(\"./best_nn.pth\")\n",
        "\n",
        "# predict\n",
        "with torch.no_grad():\n",
        "    scores = mlr_torch(torch.Tensor(X)).detach().numpy()   \n",
        "y_hat = np.argmax(scores,axis=1)\n",
        "\n",
        "# evaluate\n",
        "acc = np.mean(y_hat == y)\n",
        "print('accuracy of model: ',acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of model:  0.91358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy0Ltxg8gjwX",
        "outputId": "47f01b0c-16fa-4a42-f9b5-37530b8de74f"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class ProjectDataset(Dataset):\n",
        "\n",
        "    def __init__(self, samples, targets, transform=None):\n",
        "        self.samples = samples\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, index):  \n",
        "        label = self.targets[index]\n",
        "        sample = self.samples[index,:]\n",
        "        sample = sample.reshape(1,-1)\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        return (sample, label)\n",
        "    \n",
        "dl = DataLoader(ProjectDataset(X,y), batch_size=len(y))\n",
        "\n",
        "xx,_=next(iter(dl))\n",
        "# load a trained PyTorch model (see 'pytorch_saving_demo.ipynb')\n",
        "mlr_torch = torch.jit.load(\"./best_cnn.pth\")\n",
        "\n",
        "# predict\n",
        "with torch.no_grad():\n",
        "    scores = mlr_torch(xx.float()).detach().numpy()   \n",
        "y_hat = np.argmax(scores,axis=1)\n",
        "\n",
        "# evaluate\n",
        "acc = np.mean(y_hat == y)\n",
        "print('accuracy of model: ',acc)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of model:  0.91562\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}